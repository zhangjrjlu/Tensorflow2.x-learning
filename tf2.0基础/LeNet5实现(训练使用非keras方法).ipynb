{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import losses, optimizers\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "img_rows, img_cols = 28, 28\n",
    "# 通过Keras封装好的API加载MNIST数据。其中trainX就是一个60000 * 28 * 28的数组，\n",
    "# trainY是每一张图片对应的数字。\n",
    "def load_data(path='/Users/zhangjrjlu/datasets/mnist.npz'):       #####该部分是对于.npz(numpy格式)文件的读取方法\n",
    "    f = np.load(path)\n",
    "    x_train, y_train = f['x_train'], f['y_train']\n",
    "    x_test, y_test = f['x_test'], f['y_test']\n",
    "    f.close()\n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    " \n",
    "# the data, split between train and test sets\n",
    "(trainX, trainY), (testX, testY) = load_data()\n",
    "\n",
    "# 根据对图像编码的格式要求来设置输入层的格式。需要根据对于图像格式的要求来判断\n",
    "if K.image_data_format() == 'channels_first':     \n",
    "    trainX = trainX.reshape(trainX.shape[0], 1, img_rows, img_cols)   #四维数组，第一项是图片的数量，表示第几张图片\n",
    "    testX = testX.reshape(testX.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    trainX = trainX.reshape(trainX.shape[0], img_rows, img_cols, 1)\n",
    "    testX = testX.reshape(testX.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "trainX = trainX.astype('float32')\n",
    "testX = testX.astype('float32')\n",
    "trainX /= 255.0\n",
    "testX /= 255.0\n",
    "trainY = keras.utils.to_categorical(trainY, 10)\n",
    "testY = keras.utils.to_categorical(testY, 10)\n",
    "x = testX\n",
    "y = testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(trainX, trainY, testX, testY):\n",
    "    #把np格式转换为张量格式\n",
    "    trainX = tf.convert_to_tensor(trainX, dtype=tf.float32)\n",
    "    trainY = tf.convert_to_tensor(trainY, dtype=tf.int32)\n",
    "    testX = tf.convert_to_tensor(testX, dtype=tf.float32)\n",
    "    testY = tf.convert_to_tensor(testY, dtype=tf.int32)\n",
    "    \n",
    "#     trainY = tf.cast(trainY, dtype=tf.int32)\n",
    "#     testY = tf.cast(testY, dtype=tf.int32)\n",
    "#     trainY = tf.one_hot(trainY, depth=10)\n",
    "#     testY = tf.one_hot(testY, depth=10)\n",
    "    \n",
    "    return trainX, trainY, testX, testY\n",
    "\n",
    "trainX, trainY, testX, testY = convert(trainX, trainY, testX, testY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_18 (Conv2D)           (None, 26, 26, 6)         60        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 13, 13, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 11, 11, 16)        880       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 120)               48120     \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 60,074\n",
      "Trainable params: 60,074\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(6, kernel_size=3, strides=1, activation='relu', input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(16, kernel_size=3, strides=1, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(120, activation='relu'))\n",
    "model.add(Dense(84, activation='relu'))\n",
    "model.add(Dense(10))\n",
    "\"\"\"\n",
    "如果想要在这里使用激活函数可以使用model.add(Dense(10, activation='softmax'))\n",
    "因为当前程序为了使用tensorflow的方法实现，因此不再这里进行激活\n",
    "\"\"\"\n",
    "model.build(input_shape=(60000, 28, 28, 1))\n",
    "\"\"\"\n",
    "使用Sequential()中的build函数进行初始化必须是四维，第一维度是输入的数量\n",
    "在model.layers中初始化，只能初始化图片的维度三维，可以是channel first，也可以是channel last\n",
    "\"\"\"\n",
    "#model.build(input_shape=input_shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = losses.CategoricalCrossentropy(from_logits=True)\n",
    "\"\"\"\n",
    "losses.CategoricalCrossentropy是交叉熵损失函数类，当参数from_logits为True的时候，会把softmax激活函数实现在损失函数中\n",
    "也可以直接使用\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.SGD(),metrics=['accuracy'])\n",
    "直接把把损失函数，优化函数以及评测方法写入\n",
    "\"\"\"\n",
    "def train(cross_entropy, X, Y, model):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_ = model(X)\n",
    "        loss = cross_entropy(Y, y_)\n",
    "    grad = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizers.Adam().apply_gradients(zip(grad, model.trainable_variables))\n",
    "\n",
    "for i in range(40):\n",
    "    train(cross_entropy, trainX, trainY, model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.54380435, shape=(), dtype=float32)\n",
      "tf.Tensor(0.8396, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "c, t = 0, 0\n",
    "out = model(testX)\n",
    "loss = cross_entropy(testY, out)\n",
    "print(loss)\n",
    "correct_prediction = tf.equal(tf.argmax(out, 1), tf.argmax(testY, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 7s 114us/sample - loss: 1.6203 - accuracy: 0.5160 - val_loss: 0.5194 - val_accuracy: 0.8513\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.4034 - accuracy: 0.8780 - val_loss: 0.3155 - val_accuracy: 0.9037\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 0.2776 - accuracy: 0.9140 - val_loss: 0.2476 - val_accuracy: 0.9208\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 0.2174 - accuracy: 0.9334 - val_loss: 0.1804 - val_accuracy: 0.9407\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.1799 - accuracy: 0.9456 - val_loss: 0.1539 - val_accuracy: 0.9540\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 0.1533 - accuracy: 0.9534 - val_loss: 0.1406 - val_accuracy: 0.9554\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 0.1348 - accuracy: 0.9589 - val_loss: 0.1328 - val_accuracy: 0.9589\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 0.1207 - accuracy: 0.9629 - val_loss: 0.1127 - val_accuracy: 0.9641\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 0.1115 - accuracy: 0.9651 - val_loss: 0.0988 - val_accuracy: 0.9674\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.1025 - accuracy: 0.9684 - val_loss: 0.0977 - val_accuracy: 0.9702\n",
      "10000/10000 [==============================] - 1s 54us/sample - loss: 0.0977 - accuracy: 0.9702\n",
      "Test loss: 0.09774343351796269\n",
      "Test accuracy: 0.9702\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.SGD(),\n",
    "              metrics=['accuracy'])\n",
    "model.fit(trainX, trainY,\n",
    "          batch_size=128,\n",
    "          epochs=10,\n",
    "          validation_data=(testX, testY))  \n",
    "score = model.evaluate(testX, testY)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
