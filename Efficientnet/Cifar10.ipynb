{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(10000, 32, 32, 3)\n",
      "(50000, 10)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import efficientnet.tfkeras as efn\n",
    "\n",
    "from tensorflow.keras import layers, optimizers, datasets, Sequential, losses\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, GlobalAveragePooling2D\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "def load_dataset():\n",
    "    # 在线下载，加载 CIFAR10 数据集\n",
    "    (X_train, y_train), (X_test, y_test) = datasets.cifar10.load_data()\n",
    "    # 删除 y 的一个维度， [b,1] => [b]\n",
    "    y_train = tf.squeeze(y_train, axis=1)\n",
    "    y_test = tf.squeeze(y_test, axis=1)\n",
    "    # 构建训练集对象，随机打乱，预处理，批量化\n",
    "    \"\"\"\n",
    "    tf.data.Dataset.from_tensor_slices()的输入可以是numpy也可以是tensor，如果是numpy会自动转化为tensor。\n",
    "    tf.data.Dataset.shuffle()函数的作用是打乱数据，参数为缓冲区的数据条数\n",
    "    map表示预处理,参数为与处理函数\n",
    "    \"\"\"\n",
    "    train_db = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "    train_db = train_db.shuffle(1000).map(preprocess).batch(128)\n",
    "    # 构建测试集对象，预处理，批量化\n",
    "    test_db = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "    test_db = test_db.map(preprocess).batch(64)\n",
    "    # 从训练集中采样一个 Batch，并观察\n",
    "    sample = next(iter(train_db))\n",
    "    #print('sample:', sample[0].shape, sample[1].shape, tf.reduce_min(sample[0]), tf.reduce_max(sample[0]))\n",
    "    return train_db, test_db\n",
    "\n",
    "def preprocess(x, y):\n",
    "    x = 2 * tf.cast(x, dtype=tf.float32) / 255. - 1\n",
    "    y = tf.cast(y, dtype=tf.int32)\n",
    "    return x, y\n",
    "\n",
    "def load_dataset1():\n",
    "    # 在线下载，加载 CIFAR10 数据集\n",
    "    (X_train, y_train), (X_test, y_test) = datasets.cifar10.load_data()\n",
    "    # 删除 y 的一个维度， [b,1] => [b]\n",
    "    #y_train = tf.squeeze(y_train, axis=1)\n",
    "    #y_test = tf.squeeze(y_test, axis=1)\n",
    "    #(X_train, y_train) = shuffle((X_train, y_train))\n",
    "    X_train, y_train = preprocess(X_train, y_train)\n",
    "    X_test, y_test = preprocess(X_test, y_test)\n",
    "    y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "    y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "#train_db, test_db = load_dataset()\n",
    "X_train, y_train, X_test, y_test = load_dataset1()\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model():\n",
    "    baseline = efn.EfficientNetB7(input_shape=(32,32,3), weights='imagenet', include_top=False)\n",
    "    model = Sequential()\n",
    "    model.add(baseline)\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Flatten())###把上层的输出拉平\n",
    "    model.add(Dense(10, activation=\"softmax\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.5125 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.525 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.5375 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.55 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.5625 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "model.compile(loss=tf.keras.losses.categorical_crossentropy, optimizer=optimizers.Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "50000/50000 [==============================] - 143s 3ms/sample - loss: 1.0585 - accuracy: 0.6354 - val_loss: 0.6953 - val_accuracy: 0.7889\n",
      "Epoch 2/15\n",
      "50000/50000 [==============================] - 105s 2ms/sample - loss: 0.5193 - accuracy: 0.8287 - val_loss: 0.5445 - val_accuracy: 0.8287\n",
      "Epoch 3/15\n",
      "50000/50000 [==============================] - 105s 2ms/sample - loss: 0.3741 - accuracy: 0.8764 - val_loss: 0.4707 - val_accuracy: 0.8487\n",
      "Epoch 4/15\n",
      "50000/50000 [==============================] - 105s 2ms/sample - loss: 0.3045 - accuracy: 0.8999 - val_loss: 0.4714 - val_accuracy: 0.8565\n",
      "Epoch 5/15\n",
      "50000/50000 [==============================] - 105s 2ms/sample - loss: 0.2380 - accuracy: 0.9193 - val_loss: 0.5079 - val_accuracy: 0.8508\n",
      "Epoch 6/15\n",
      "50000/50000 [==============================] - 105s 2ms/sample - loss: 0.1813 - accuracy: 0.9394 - val_loss: 0.5453 - val_accuracy: 0.8538\n",
      "Epoch 7/15\n",
      "50000/50000 [==============================] - 105s 2ms/sample - loss: 0.1675 - accuracy: 0.9449 - val_loss: 0.5591 - val_accuracy: 0.8476\n",
      "Epoch 8/15\n",
      "50000/50000 [==============================] - 103s 2ms/sample - loss: 0.1419 - accuracy: 0.9531 - val_loss: 0.5435 - val_accuracy: 0.8540\n",
      "Epoch 9/15\n",
      "50000/50000 [==============================] - 105s 2ms/sample - loss: 0.1418 - accuracy: 0.9526 - val_loss: 0.5552 - val_accuracy: 0.8558\n",
      "Epoch 10/15\n",
      "50000/50000 [==============================] - 105s 2ms/sample - loss: 0.1213 - accuracy: 0.9601 - val_loss: 0.5239 - val_accuracy: 0.8692\n",
      "Epoch 11/15\n",
      "50000/50000 [==============================] - 105s 2ms/sample - loss: 0.1013 - accuracy: 0.9670 - val_loss: 0.5156 - val_accuracy: 0.8656\n",
      "Epoch 12/15\n",
      "50000/50000 [==============================] - 105s 2ms/sample - loss: 0.0960 - accuracy: 0.9679 - val_loss: 0.5706 - val_accuracy: 0.8630\n",
      "Epoch 13/15\n",
      "50000/50000 [==============================] - 106s 2ms/sample - loss: 0.0891 - accuracy: 0.9716 - val_loss: 0.5662 - val_accuracy: 0.8645\n",
      "Epoch 14/15\n",
      "50000/50000 [==============================] - 105s 2ms/sample - loss: 0.0819 - accuracy: 0.9732 - val_loss: 0.5419 - val_accuracy: 0.8674\n",
      "Epoch 15/15\n",
      "50000/50000 [==============================] - 105s 2ms/sample - loss: 0.0795 - accuracy: 0.9737 - val_loss: 0.5739 - val_accuracy: 0.8617\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2637bc36fc8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=128, epochs=15, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
