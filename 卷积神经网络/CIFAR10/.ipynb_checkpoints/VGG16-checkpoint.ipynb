{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(10000, 32, 32, 3)\n",
      "(50000, 10)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras import layers, optimizers, datasets, Sequential, losses\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "def load_dataset():\n",
    "    # 在线下载，加载 CIFAR10 数据集\n",
    "    (X_train, y_train), (X_test, y_test) = datasets.cifar10.load_data()\n",
    "    # 删除 y 的一个维度， [b,1] => [b]\n",
    "    y_train = tf.squeeze(y_train, axis=1)\n",
    "    y_test = tf.squeeze(y_test, axis=1)\n",
    "    # 构建训练集对象，随机打乱，预处理，批量化\n",
    "    \"\"\"\n",
    "    tf.data.Dataset.from_tensor_slices()的输入可以是numpy也可以是tensor，如果是numpy会自动转化为tensor。\n",
    "    tf.data.Dataset.shuffle()函数的作用是打乱数据，参数为缓冲区的数据条数\n",
    "    map表示预处理,参数为与处理函数\n",
    "    \"\"\"\n",
    "    print(X_test.shape)\n",
    "    train_db = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "    train_db = train_db.shuffle(1000).map(preprocess).batch(128)\n",
    "    # 构建测试集对象，预处理，批量化\n",
    "    test_db = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "    test_db = test_db.map(preprocess).batch(64)\n",
    "    # 从训练集中采样一个 Batch，并观察\n",
    "    sample = next(iter(train_db))\n",
    "    #print('sample:', sample[0].shape, sample[1].shape, tf.reduce_min(sample[0]), tf.reduce_max(sample[0]))\n",
    "    return train_db, test_db\n",
    "\n",
    "def preprocess(x, y):\n",
    "    x = 2 * tf.cast(x, dtype=tf.float32) / 255. - 1\n",
    "    y = tf.cast(y, dtype=tf.int32)\n",
    "    return x, y\n",
    "\n",
    "def load_dataset1():\n",
    "    # 在线下载，加载 CIFAR10 数据集\n",
    "    (X_train, y_train), (X_test, y_test) = datasets.cifar10.load_data()\n",
    "    # 删除 y 的一个维度， [b,1] => [b]\n",
    "    #y_train = tf.squeeze(y_train, axis=1)\n",
    "    #y_test = tf.squeeze(y_test, axis=1)\n",
    "    #(X_train, y_train) = shuffle((X_train, y_train))\n",
    "    X_train, y_train = preprocess(X_train, y_train)\n",
    "    X_test, y_test = preprocess(X_test, y_test)\n",
    "    y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "    y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "#train_db, test_db = load_dataset()\n",
    "X_train, y_train, X_test, y_test = load_dataset1()\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_model():\n",
    "    model = Sequential()\n",
    "    # 原始图片结构32x32x3\n",
    "    model.add(layers.Conv2D(64, kernel_size=(3, 3), strides=(1, 1), padding='SAME', activation=\"relu\", input_shape=[32, 32, 3]))\n",
    "    model.add(layers.Conv2D(64, kernel_size=(3, 3), strides=(1, 1), padding='SAME', activation=\"relu\"))\n",
    "\n",
    "    model.add(layers.MaxPooling2D(pool_size=[2, 2], strides=2, padding=\"SAME\"))\n",
    "\n",
    "    # 图片结构16x16x64\n",
    "    model.add(layers.Conv2D(128, kernel_size=(3, 3), strides=(1, 1), padding='SAME', activation=\"relu\"))\n",
    "    model.add(layers.Conv2D(128, kernel_size=(3, 3), strides=(1, 1), padding='SAME', activation=\"relu\"))\n",
    "\n",
    "    model.add(layers.MaxPooling2D(pool_size=[2, 2], strides=2, padding=\"SAME\"))\n",
    "\n",
    "    # 图片结构 8x8x128\n",
    "    model.add(layers.Conv2D(256, kernel_size=(3, 3), strides=(1, 1), padding='SAME', activation=\"relu\"))\n",
    "    model.add(layers.Conv2D(256, kernel_size=(3, 3), strides=(1, 1), padding='SAME', activation=\"relu\"))\n",
    "    model.add(layers.Conv2D(256, kernel_size=(3, 3), strides=(1, 1), padding='SAME', activation=\"relu\"))\n",
    "\n",
    "    model.add(layers.MaxPooling2D(pool_size=[2, 2], strides=2, padding=\"SAME\"))\n",
    "\n",
    "    # 图片结构4x4x256\n",
    "    model.add(layers.Conv2D(512, kernel_size=(3, 3), strides=(1, 1), padding='SAME', activation=\"relu\"))\n",
    "    model.add(layers.Conv2D(512, kernel_size=(3, 3), strides=(1, 1), padding='SAME', activation=\"relu\"))\n",
    "    model.add(layers.Conv2D(512, kernel_size=(3, 3), strides=(1, 1), padding='SAME', activation=\"relu\"))\n",
    "\n",
    "    # 少进行一次池化\n",
    "    # model.add(layers.MaxPooling2D(pool_size=[2, 2], strides=2, padding=\"SAME\"))\n",
    "\n",
    "    # 图片结构4x4x512\n",
    "    model.add(layers.Conv2D(512, kernel_size=(3, 3), strides=(1, 1), padding='SAME', activation=\"relu\"))\n",
    "    model.add(layers.Conv2D(512, kernel_size=(3, 3), strides=(1, 1), padding='SAME', activation=\"relu\"))\n",
    "    model.add(layers.Conv2D(512, kernel_size=(3, 3), strides=(1, 1), padding='SAME', activation=\"relu\"))\n",
    "\n",
    "    model.add(layers.MaxPooling2D(pool_size=[2, 2], strides=2, padding=\"SAME\"))\n",
    "\n",
    "    # 图片结构2x2x512\n",
    "    model.add(layers.Flatten())     # 把上层输入拉平\n",
    "    model.add(layers.Dense(units=256, activation=\"relu\"))\n",
    "    model.add(layers.Dense(units=128, activation=\"relu\"))\n",
    "    model.add(layers.Dense(units=10, activation=\"softmax\"))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               524544    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 15,273,418\n",
      "Trainable params: 15,273,418\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = network_model()\n",
    "model.compile(loss=tf.keras.losses.categorical_crossentropy, optimizer=optimizers.Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " 3328/50000 [>.............................] - ETA: 2:07 - loss: 2.3047 - accuracy: 0.0931"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=128, epochs=10, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
