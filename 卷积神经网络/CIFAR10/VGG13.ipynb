{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(10000, 32, 32, 3)\n",
      "(50000, 10)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras import layers, optimizers, datasets, Sequential, losses\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "def load_dataset():\n",
    "    # 在线下载，加载 CIFAR10 数据集\n",
    "    (X_train, y_train), (X_test, y_test) = datasets.cifar10.load_data()\n",
    "    # 删除 y 的一个维度， [b,1] => [b]\n",
    "    y_train = tf.squeeze(y_train, axis=1)\n",
    "    y_test = tf.squeeze(y_test, axis=1)\n",
    "    # 构建训练集对象，随机打乱，预处理，批量化\n",
    "    \"\"\"\n",
    "    tf.data.Dataset.from_tensor_slices()的输入可以是numpy也可以是tensor，如果是numpy会自动转化为tensor。\n",
    "    tf.data.Dataset.shuffle()函数的作用是打乱数据，参数为缓冲区的数据条数\n",
    "    map表示预处理,参数为与处理函数\n",
    "    \"\"\"\n",
    "    print(X_test.shape)\n",
    "    train_db = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "    train_db = train_db.shuffle(1000).map(preprocess).batch(128)\n",
    "    # 构建测试集对象，预处理，批量化\n",
    "    test_db = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "    test_db = test_db.map(preprocess).batch(64)\n",
    "    # 从训练集中采样一个 Batch，并观察\n",
    "    sample = next(iter(train_db))\n",
    "    #print('sample:', sample[0].shape, sample[1].shape, tf.reduce_min(sample[0]), tf.reduce_max(sample[0]))\n",
    "    return train_db, test_db\n",
    "\n",
    "def preprocess(x, y):\n",
    "    x = 2 * tf.cast(x, dtype=tf.float32) / 255. - 1\n",
    "    y = tf.cast(y, dtype=tf.int32)\n",
    "    return x, y\n",
    "\n",
    "def load_dataset1():\n",
    "    # 在线下载，加载 CIFAR10 数据集\n",
    "    (X_train, y_train), (X_test, y_test) = datasets.cifar10.load_data()\n",
    "    # 删除 y 的一个维度， [b,1] => [b]\n",
    "    #y_train = tf.squeeze(y_train, axis=1)\n",
    "    #y_test = tf.squeeze(y_test, axis=1)\n",
    "    #(X_train, y_train) = shuffle((X_train, y_train))\n",
    "    X_train, y_train = preprocess(X_train, y_train)\n",
    "    X_test, y_test = preprocess(X_test, y_test)\n",
    "    y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "    y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "#train_db, test_db = load_dataset()\n",
    "X_train, y_train, X_test, y_test = load_dataset1()\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, kernel_size=(3,3), padding=\"same\", activation=\"relu\", input_shape=[32, 32, 3]))\n",
    "    model.add(Conv2D(64, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=2, padding=\"same\"))\n",
    "        \n",
    "    model.add(Conv2D(128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(Conv2D(128, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=2, padding=\"same\"))\n",
    "\n",
    "    model.add(Conv2D(256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(Conv2D(256, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=2, padding=\"same\"))\n",
    "\n",
    "    model.add(Conv2D(512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(Conv2D(512, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=2, padding=\"same\"))\n",
    "    \n",
    "    model.add(Conv2D(512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(Conv2D(512, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=2, padding=\"same\"))\n",
    "    \n",
    "    model.add(Flatten())###把上层的输出拉平\n",
    "    model.add(Dense(256, activation=tf.nn.relu))\n",
    "    model.add(Dense(128, activation=tf.nn.relu))\n",
    "    model.add(Dense(10, activation=\"softmax\"))\n",
    "    \n",
    "    #model.summary()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = network_model()\n",
    "model.compile(loss=tf.keras.losses.categorical_crossentropy, optimizer=optimizers.Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "50000/50000 [==============================] - 24s 488us/sample - loss: 2.3028 - accuracy: 0.0981 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 2/15\n",
      "50000/50000 [==============================] - 18s 369us/sample - loss: 2.3027 - accuracy: 0.0982 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 3/15\n",
      "50000/50000 [==============================] - 19s 370us/sample - loss: 2.3027 - accuracy: 0.0978 - val_loss: 2.3026 - val_accuracy: 0.1000\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=128, epochs=15, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
